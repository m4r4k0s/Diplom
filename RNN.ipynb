{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a471517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d9b5dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.layers import Dense, GRU,LSTM, Input, Dropout, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "810edbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61200, 768)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"BERT_embeds.pkl\", \"rb\") as file_to_read:\n",
    "    corpus_embeds = pickle.load(file_to_read)\n",
    "    \n",
    "corpus_embeds_np = np.asarray(corpus_embeds)\n",
    "corpus_embeds_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6101372",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0d0a36d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61200,)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"Classes_KMeans_3.pkl\", \"rb\") as file_to_read:\n",
    "    classes_KM = pickle.load(file_to_read)\n",
    "    \n",
    "classes_KM_np = np.asarray(classes_KM)\n",
    "classes_KM_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "101b04f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19387 41813 61200\n"
     ]
    }
   ],
   "source": [
    "total_lines = classes_KM_np.shape[0]\n",
    "count_true = classes_KM_np.sum()\n",
    "count_false = classes_KM_np.shape[0] - classes_KM_np.sum()\n",
    "print(count_true, count_false, total_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "616aa51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61200, 768) (61200, 2)\n"
     ]
    }
   ],
   "source": [
    "X = corpus_embeds_np\n",
    "Y = np.array([[1, 0]]*count_true + [[0, 1]]*count_false)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "04704f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (total_lines):\n",
    "    if classes_KM_np[i] == 0:\n",
    "        Y[i] = np.array([[1,0]])\n",
    "    if classes_KM_np[i]==1:\n",
    "        Y[i] = np.array([[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d03f1f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61195</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61197</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61199</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5\n",
       "0      0  0  0  0  0  1\n",
       "1      0  0  0  0  1  0\n",
       "2      0  0  0  1  0  0\n",
       "3      0  0  1  0  0  0\n",
       "4      0  0  0  0  1  0\n",
       "...   .. .. .. .. .. ..\n",
       "61195  0  1  0  0  0  0\n",
       "61196  0  0  0  1  0  0\n",
       "61197  0  1  0  0  0  0\n",
       "61198  0  0  1  0  0  0\n",
       "61199  0  0  0  0  1  0\n",
       "\n",
       "[61200 rows x 6 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_KM_np_dum = pd.get_dummies(classes_KM_np)\n",
    "classes_KM_np_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "367b5dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 768, 128)          128000    \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 768, 128)          99072     \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,450\n",
      "Trainable params: 264,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Embedding(1000, 128, input_length = 768))\n",
    "model_1.add(GRU(128, return_sequences=True))\n",
    "model_1.add(GRU(64))\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "model_1.summary()\n",
    "\n",
    "model_1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e06a140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 768, 128)          128000    \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 768, 128)          99072     \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,450\n",
      "Trainable params: 264,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(1000, 128, input_length = 768))\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(GRU(64))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(0.0001))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fee0ce2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1913/1913 [==============================] - 81s 42ms/step - loss: 0.3187 - accuracy: 0.8608\n",
      "Epoch 2/50\n",
      "1913/1913 [==============================] - 79s 41ms/step - loss: 0.1838 - accuracy: 0.9376\n",
      "Epoch 3/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1700 - accuracy: 0.9426\n",
      "Epoch 4/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1562 - accuracy: 0.9464\n",
      "Epoch 5/50\n",
      "1913/1913 [==============================] - 81s 42ms/step - loss: 0.1385 - accuracy: 0.9517\n",
      "Epoch 6/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0772 - accuracy: 0.9728\n",
      "Epoch 7/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0506 - accuracy: 0.9816\n",
      "Epoch 8/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0481 - accuracy: 0.9815\n",
      "Epoch 9/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0451 - accuracy: 0.9825\n",
      "Epoch 10/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0440 - accuracy: 0.9833\n",
      "Epoch 11/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0412 - accuracy: 0.9841\n",
      "Epoch 12/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0379 - accuracy: 0.9850\n",
      "Epoch 13/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0359 - accuracy: 0.9864\n",
      "Epoch 14/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0345 - accuracy: 0.9865\n",
      "Epoch 15/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0329 - accuracy: 0.9873\n",
      "Epoch 16/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0320 - accuracy: 0.9879\n",
      "Epoch 17/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0310 - accuracy: 0.9882\n",
      "Epoch 18/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0299 - accuracy: 0.9886\n",
      "Epoch 19/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0291 - accuracy: 0.9888\n",
      "Epoch 20/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0280 - accuracy: 0.9894\n",
      "Epoch 21/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0274 - accuracy: 0.9892\n",
      "Epoch 22/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0265 - accuracy: 0.9897\n",
      "Epoch 23/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0266 - accuracy: 0.9896\n",
      "Epoch 24/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0257 - accuracy: 0.9896\n",
      "Epoch 25/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0252 - accuracy: 0.9898\n",
      "Epoch 26/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0243 - accuracy: 0.9910\n",
      "Epoch 27/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0234 - accuracy: 0.9906\n",
      "Epoch 28/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0229 - accuracy: 0.9911\n",
      "Epoch 29/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0224 - accuracy: 0.9908\n",
      "Epoch 30/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0213 - accuracy: 0.9914\n",
      "Epoch 31/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0205 - accuracy: 0.9920\n",
      "Epoch 32/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0204 - accuracy: 0.9921\n",
      "Epoch 33/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0197 - accuracy: 0.9922\n",
      "Epoch 34/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0192 - accuracy: 0.9925\n",
      "Epoch 35/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0190 - accuracy: 0.9927\n",
      "Epoch 36/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0186 - accuracy: 0.9926\n",
      "Epoch 37/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0186 - accuracy: 0.9924\n",
      "Epoch 38/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0179 - accuracy: 0.9930\n",
      "Epoch 39/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0180 - accuracy: 0.9926\n",
      "Epoch 40/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0178 - accuracy: 0.9926\n",
      "Epoch 41/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0175 - accuracy: 0.9927\n",
      "Epoch 42/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0175 - accuracy: 0.9928\n",
      "Epoch 43/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0172 - accuracy: 0.9929\n",
      "Epoch 44/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0167 - accuracy: 0.9931\n",
      "Epoch 45/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0167 - accuracy: 0.9932\n",
      "Epoch 46/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0165 - accuracy: 0.9933\n",
      "Epoch 47/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0164 - accuracy: 0.9932\n",
      "Epoch 48/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0161 - accuracy: 0.9934\n",
      "Epoch 49/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0159 - accuracy: 0.9937\n",
      "Epoch 50/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.0156 - accuracy: 0.9934\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(X, Y, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "170b83c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1913/1913 [==============================] - 81s 42ms/step - loss: 0.4345 - accuracy: 0.7893\n",
      "Epoch 2/50\n",
      "1913/1913 [==============================] - 79s 41ms/step - loss: 0.2941 - accuracy: 0.8813\n",
      "Epoch 3/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2639 - accuracy: 0.8906\n",
      "Epoch 4/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2532 - accuracy: 0.8945\n",
      "Epoch 5/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2478 - accuracy: 0.8954\n",
      "Epoch 6/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2429 - accuracy: 0.8975\n",
      "Epoch 7/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2874 - accuracy: 0.8811\n",
      "Epoch 8/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2376 - accuracy: 0.8987\n",
      "Epoch 9/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2354 - accuracy: 0.8999\n",
      "Epoch 10/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2319 - accuracy: 0.9012\n",
      "Epoch 11/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2282 - accuracy: 0.9029\n",
      "Epoch 12/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2247 - accuracy: 0.9051\n",
      "Epoch 13/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2193 - accuracy: 0.9072\n",
      "Epoch 14/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2163 - accuracy: 0.9089\n",
      "Epoch 15/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2126 - accuracy: 0.9107\n",
      "Epoch 16/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2070 - accuracy: 0.9144\n",
      "Epoch 17/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2083 - accuracy: 0.9131\n",
      "Epoch 18/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2033 - accuracy: 0.9155\n",
      "Epoch 19/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.2015 - accuracy: 0.9166\n",
      "Epoch 20/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1989 - accuracy: 0.9179\n",
      "Epoch 21/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1997 - accuracy: 0.9194\n",
      "Epoch 22/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1922 - accuracy: 0.9217\n",
      "Epoch 23/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1952 - accuracy: 0.9196\n",
      "Epoch 24/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1926 - accuracy: 0.9218\n",
      "Epoch 25/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1909 - accuracy: 0.9217\n",
      "Epoch 26/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1908 - accuracy: 0.9224\n",
      "Epoch 27/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1917 - accuracy: 0.9224\n",
      "Epoch 28/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1853 - accuracy: 0.9252\n",
      "Epoch 29/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1836 - accuracy: 0.9267\n",
      "Epoch 30/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1851 - accuracy: 0.9251\n",
      "Epoch 31/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1821 - accuracy: 0.9262\n",
      "Epoch 32/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1813 - accuracy: 0.9270\n",
      "Epoch 33/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1806 - accuracy: 0.9276\n",
      "Epoch 34/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1861 - accuracy: 0.9255\n",
      "Epoch 35/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1787 - accuracy: 0.9286\n",
      "Epoch 36/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1808 - accuracy: 0.9281\n",
      "Epoch 37/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1778 - accuracy: 0.9288\n",
      "Epoch 38/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1758 - accuracy: 0.9305\n",
      "Epoch 39/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1740 - accuracy: 0.9304\n",
      "Epoch 40/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1808 - accuracy: 0.9279\n",
      "Epoch 41/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1728 - accuracy: 0.9315\n",
      "Epoch 42/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1698 - accuracy: 0.9333\n",
      "Epoch 43/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1703 - accuracy: 0.9330\n",
      "Epoch 44/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1696 - accuracy: 0.9334\n",
      "Epoch 45/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1837 - accuracy: 0.9259\n",
      "Epoch 46/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1662 - accuracy: 0.9349\n",
      "Epoch 47/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1634 - accuracy: 0.9369\n",
      "Epoch 48/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1709 - accuracy: 0.9330\n",
      "Epoch 49/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1667 - accuracy: 0.9342\n",
      "Epoch 50/50\n",
      "1913/1913 [==============================] - 80s 42ms/step - loss: 0.1620 - accuracy: 0.9372\n"
     ]
    }
   ],
   "source": [
    "history_1 = model.fit(X, Y, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f9982e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "from multiprocessing import Process, Lock\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "339dd011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased-conversational were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased-conversational\")\n",
    "model_bert = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased-conversational\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1a1ef263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_transf(text, batch_l = 2):\n",
    "    train_encodings = tokenizer(text, truncation=True, padding='max_length', max_length=256)\n",
    "    input_ids = torch.tensor(train_encodings['input_ids'])\n",
    "    BATCH_LENGTH = batch_l\n",
    "    embeddings = np.empty((0,768))\n",
    "    device = torch.device(\"cuda\")\n",
    "    device2 = torch.device(\"cpu\")\n",
    "    model_bert.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        for batch_num in range(int(len(input_ids) / BATCH_LENGTH)):\n",
    "            try:\n",
    "                batch = input_ids[batch_num * BATCH_LENGTH : (batch_num + 1) * BATCH_LENGTH].cuda()\n",
    "                results = model_bert(batch)\n",
    "                head_output = results[0][:,0,:].cpu().detach().numpy()\n",
    "                embeddings = np.concatenate((embeddings, head_output))\n",
    "                print(f\"processed batch {batch_num}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "    res = model_1.predict(embeddings)\n",
    "    print(res, np.argmax(res), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6dd958bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed batch 0\n",
      "[[9.9999654e-01 3.4453303e-06]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "t = ['павел любовь значит наша ограбить ключи готов и у меня одного ключа не хватает прав да прибор листочек не дали не медали минутку сейчас я подниму перешлю вам хорошо когда рассказываешь хорошо ']\n",
    "emb = bert_transf(t, batch_l = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda3944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "64ffbcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9991965e-01 8.0342274e-05]]\n"
     ]
    }
   ],
   "source": [
    "res = model_1.predict(X[0:1])\n",
    "print(res, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "155bc583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_KM_np[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "710d9dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if res[0][0]>res[0][1]:\n",
    "    print('0')\n",
    "else:\n",
    "    print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "575134d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 768, 128)          128000    \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, 768, 128)          99072     \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,710\n",
      "Trainable params: 264,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Embedding(1000, 128, input_length = 768))\n",
    "model_2.add(GRU(128, return_sequences=True))\n",
    "model_2.add(GRU(64))\n",
    "model_2.add(Dense(6, activation='softmax'))\n",
    "model_2.summary()\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "74491f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, classes_KM_np_dum, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "01fde06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1722/1722 [==============================] - 89s 46ms/step - loss: 1.4641 - accuracy: 0.4044 - val_loss: 1.2720 - val_accuracy: 0.4887\n",
      "Epoch 2/50\n",
      "1722/1722 [==============================] - 75s 43ms/step - loss: 1.1817 - accuracy: 0.5233 - val_loss: 1.0434 - val_accuracy: 0.5729\n",
      "Epoch 3/50\n",
      "1722/1722 [==============================] - 75s 44ms/step - loss: 1.0060 - accuracy: 0.5884 - val_loss: 0.9486 - val_accuracy: 0.6095\n",
      "Epoch 4/50\n",
      "1722/1722 [==============================] - 75s 44ms/step - loss: 0.9293 - accuracy: 0.6183 - val_loss: 0.8846 - val_accuracy: 0.6386\n",
      "Epoch 5/50\n",
      "1722/1722 [==============================] - 75s 44ms/step - loss: 0.8951 - accuracy: 0.6351 - val_loss: 0.8709 - val_accuracy: 0.6371\n",
      "Epoch 6/50\n",
      "1722/1722 [==============================] - 75s 44ms/step - loss: 0.8747 - accuracy: 0.6442 - val_loss: 0.8943 - val_accuracy: 0.6261\n",
      "Epoch 7/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8603 - accuracy: 0.6518 - val_loss: 0.8519 - val_accuracy: 0.6518\n",
      "Epoch 8/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8517 - accuracy: 0.6566 - val_loss: 0.8443 - val_accuracy: 0.6578\n",
      "Epoch 9/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8411 - accuracy: 0.6619 - val_loss: 0.8449 - val_accuracy: 0.6577\n",
      "Epoch 10/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8294 - accuracy: 0.6669 - val_loss: 0.8189 - val_accuracy: 0.6660\n",
      "Epoch 11/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8181 - accuracy: 0.6731 - val_loss: 0.7888 - val_accuracy: 0.6858\n",
      "Epoch 12/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8043 - accuracy: 0.6797 - val_loss: 0.7734 - val_accuracy: 0.6920\n",
      "Epoch 13/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7920 - accuracy: 0.6847 - val_loss: 0.7665 - val_accuracy: 0.6980\n",
      "Epoch 14/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7811 - accuracy: 0.6909 - val_loss: 0.7573 - val_accuracy: 0.7007\n",
      "Epoch 15/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7697 - accuracy: 0.6968 - val_loss: 0.7648 - val_accuracy: 0.6995\n",
      "Epoch 16/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7620 - accuracy: 0.6994 - val_loss: 0.7380 - val_accuracy: 0.7083\n",
      "Epoch 17/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7523 - accuracy: 0.7052 - val_loss: 0.7491 - val_accuracy: 0.7065\n",
      "Epoch 18/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7422 - accuracy: 0.7097 - val_loss: 0.7223 - val_accuracy: 0.7154\n",
      "Epoch 19/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7311 - accuracy: 0.7155 - val_loss: 0.7193 - val_accuracy: 0.7181\n",
      "Epoch 20/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7178 - accuracy: 0.7204 - val_loss: 0.7253 - val_accuracy: 0.7191\n",
      "Epoch 21/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7077 - accuracy: 0.7260 - val_loss: 0.6993 - val_accuracy: 0.7247\n",
      "Epoch 22/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6976 - accuracy: 0.7293 - val_loss: 0.6965 - val_accuracy: 0.7275\n",
      "Epoch 23/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6901 - accuracy: 0.7321 - val_loss: 0.6841 - val_accuracy: 0.7327\n",
      "Epoch 24/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6816 - accuracy: 0.7364 - val_loss: 0.6791 - val_accuracy: 0.7397\n",
      "Epoch 25/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6752 - accuracy: 0.7402 - val_loss: 0.6689 - val_accuracy: 0.7381\n",
      "Epoch 26/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6654 - accuracy: 0.7445 - val_loss: 0.6447 - val_accuracy: 0.7484\n",
      "Epoch 27/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6584 - accuracy: 0.7464 - val_loss: 0.6375 - val_accuracy: 0.7546\n",
      "Epoch 28/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6497 - accuracy: 0.7514 - val_loss: 0.6345 - val_accuracy: 0.7531\n",
      "Epoch 29/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6432 - accuracy: 0.7542 - val_loss: 0.6391 - val_accuracy: 0.7546\n",
      "Epoch 30/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6364 - accuracy: 0.7562 - val_loss: 0.6314 - val_accuracy: 0.7587\n",
      "Epoch 31/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6277 - accuracy: 0.7622 - val_loss: 0.6243 - val_accuracy: 0.7608\n",
      "Epoch 32/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6218 - accuracy: 0.7623 - val_loss: 0.6185 - val_accuracy: 0.7618\n",
      "Epoch 33/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6159 - accuracy: 0.7644 - val_loss: 0.6013 - val_accuracy: 0.7739\n",
      "Epoch 34/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6096 - accuracy: 0.7680 - val_loss: 0.6155 - val_accuracy: 0.7673\n",
      "Epoch 35/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6043 - accuracy: 0.7693 - val_loss: 0.5963 - val_accuracy: 0.7748\n",
      "Epoch 36/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5983 - accuracy: 0.7711 - val_loss: 0.5919 - val_accuracy: 0.7719\n",
      "Epoch 37/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5930 - accuracy: 0.7739 - val_loss: 0.5859 - val_accuracy: 0.7773\n",
      "Epoch 38/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5879 - accuracy: 0.7754 - val_loss: 0.5728 - val_accuracy: 0.7796\n",
      "Epoch 39/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5825 - accuracy: 0.7769 - val_loss: 0.5713 - val_accuracy: 0.7822\n",
      "Epoch 40/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5778 - accuracy: 0.7800 - val_loss: 0.6004 - val_accuracy: 0.7734\n",
      "Epoch 41/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5745 - accuracy: 0.7797 - val_loss: 0.5682 - val_accuracy: 0.7868\n",
      "Epoch 42/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5694 - accuracy: 0.7823 - val_loss: 0.5773 - val_accuracy: 0.7817\n",
      "Epoch 43/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5652 - accuracy: 0.7839 - val_loss: 0.5737 - val_accuracy: 0.7807\n",
      "Epoch 44/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5603 - accuracy: 0.7843 - val_loss: 0.5619 - val_accuracy: 0.7835\n",
      "Epoch 45/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5570 - accuracy: 0.7868 - val_loss: 0.5622 - val_accuracy: 0.7855\n",
      "Epoch 46/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5517 - accuracy: 0.7886 - val_loss: 0.5742 - val_accuracy: 0.7812\n",
      "Epoch 47/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5495 - accuracy: 0.7885 - val_loss: 0.5499 - val_accuracy: 0.7900\n",
      "Epoch 48/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5444 - accuracy: 0.7920 - val_loss: 0.5859 - val_accuracy: 0.7721\n",
      "Epoch 49/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5413 - accuracy: 0.7931 - val_loss: 0.5492 - val_accuracy: 0.7918\n",
      "Epoch 50/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5382 - accuracy: 0.7940 - val_loss: 0.5450 - val_accuracy: 0.7910\n"
     ]
    }
   ],
   "source": [
    "history_3 = model_2.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4d8efdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, 768, 128)          128000    \n",
      "                                                                 \n",
      " gru_16 (GRU)                (None, 768, 128)          99072     \n",
      "                                                                 \n",
      " gru_17 (GRU)                (None, 64)                37248     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,710\n",
      "Trainable params: 264,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Embedding(1000, 128, input_length = 768))\n",
    "model_3.add(GRU(128, return_sequences=True))\n",
    "model_3.add(GRU(64))\n",
    "model_3.add(Dropout(0.8))\n",
    "model_3.add(Dense(6, activation='softmax'))\n",
    "model_3.summary()\n",
    "\n",
    "model_3.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a26a496d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1722/1722 [==============================] - 78s 44ms/step - loss: 1.6322 - accuracy: 0.3103 - val_loss: 1.3965 - val_accuracy: 0.4735\n",
      "Epoch 2/50\n",
      "1722/1722 [==============================] - 75s 44ms/step - loss: 1.3908 - accuracy: 0.4574 - val_loss: 1.2791 - val_accuracy: 0.5046\n",
      "Epoch 3/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 1.3140 - accuracy: 0.4800 - val_loss: 1.1797 - val_accuracy: 0.5224\n",
      "Epoch 4/50\n",
      "1722/1722 [==============================] - 75s 44ms/step - loss: 1.2396 - accuracy: 0.5086 - val_loss: 1.1025 - val_accuracy: 0.5642\n",
      "Epoch 5/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 1.1800 - accuracy: 0.5318 - val_loss: 1.0542 - val_accuracy: 0.5804\n",
      "Epoch 6/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 1.1283 - accuracy: 0.5596 - val_loss: 1.0151 - val_accuracy: 0.5967\n",
      "Epoch 7/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 1.1040 - accuracy: 0.5752 - val_loss: 1.0065 - val_accuracy: 0.5946\n",
      "Epoch 8/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 1.0664 - accuracy: 0.5826 - val_loss: 0.9617 - val_accuracy: 0.6150\n",
      "Epoch 9/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 1.0233 - accuracy: 0.5977 - val_loss: 0.9140 - val_accuracy: 0.6325\n",
      "Epoch 10/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.9857 - accuracy: 0.6110 - val_loss: 0.9029 - val_accuracy: 0.6332\n",
      "Epoch 11/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.9631 - accuracy: 0.6207 - val_loss: 0.8695 - val_accuracy: 0.6477\n",
      "Epoch 12/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.9206 - accuracy: 0.6404 - val_loss: 0.8450 - val_accuracy: 0.6595\n",
      "Epoch 13/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8946 - accuracy: 0.6483 - val_loss: 0.8181 - val_accuracy: 0.6672\n",
      "Epoch 14/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8781 - accuracy: 0.6593 - val_loss: 0.8004 - val_accuracy: 0.6763\n",
      "Epoch 15/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8645 - accuracy: 0.6652 - val_loss: 0.7811 - val_accuracy: 0.6877\n",
      "Epoch 16/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8495 - accuracy: 0.6727 - val_loss: 0.7677 - val_accuracy: 0.6956\n",
      "Epoch 17/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8410 - accuracy: 0.6768 - val_loss: 0.7600 - val_accuracy: 0.6987\n",
      "Epoch 18/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8334 - accuracy: 0.6827 - val_loss: 0.7529 - val_accuracy: 0.7041\n",
      "Epoch 19/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8223 - accuracy: 0.6893 - val_loss: 0.7452 - val_accuracy: 0.7093\n",
      "Epoch 20/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8117 - accuracy: 0.6951 - val_loss: 0.7337 - val_accuracy: 0.7203\n",
      "Epoch 21/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8037 - accuracy: 0.7021 - val_loss: 0.7208 - val_accuracy: 0.7265\n",
      "Epoch 22/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7928 - accuracy: 0.7082 - val_loss: 0.7105 - val_accuracy: 0.7324\n",
      "Epoch 23/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7872 - accuracy: 0.7146 - val_loss: 0.7016 - val_accuracy: 0.7364\n",
      "Epoch 24/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7751 - accuracy: 0.7197 - val_loss: 0.6873 - val_accuracy: 0.7389\n",
      "Epoch 25/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7687 - accuracy: 0.7243 - val_loss: 0.6823 - val_accuracy: 0.7399\n",
      "Epoch 26/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7592 - accuracy: 0.7289 - val_loss: 0.6898 - val_accuracy: 0.7384\n",
      "Epoch 27/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7517 - accuracy: 0.7316 - val_loss: 0.6751 - val_accuracy: 0.7459\n",
      "Epoch 28/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7459 - accuracy: 0.7328 - val_loss: 0.6677 - val_accuracy: 0.7489\n",
      "Epoch 29/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7375 - accuracy: 0.7363 - val_loss: 0.6607 - val_accuracy: 0.7493\n",
      "Epoch 30/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7331 - accuracy: 0.7383 - val_loss: 0.6757 - val_accuracy: 0.7467\n",
      "Epoch 31/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7250 - accuracy: 0.7405 - val_loss: 0.6594 - val_accuracy: 0.7538\n",
      "Epoch 32/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7148 - accuracy: 0.7460 - val_loss: 0.6561 - val_accuracy: 0.7526\n",
      "Epoch 33/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7080 - accuracy: 0.7479 - val_loss: 0.6354 - val_accuracy: 0.7608\n",
      "Epoch 34/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6988 - accuracy: 0.7500 - val_loss: 0.6339 - val_accuracy: 0.7613\n",
      "Epoch 35/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6970 - accuracy: 0.7503 - val_loss: 0.6242 - val_accuracy: 0.7670\n",
      "Epoch 36/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6893 - accuracy: 0.7544 - val_loss: 0.6226 - val_accuracy: 0.7605\n",
      "Epoch 37/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6791 - accuracy: 0.7584 - val_loss: 0.6137 - val_accuracy: 0.7642\n",
      "Epoch 38/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6729 - accuracy: 0.7615 - val_loss: 0.6058 - val_accuracy: 0.7712\n",
      "Epoch 39/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6681 - accuracy: 0.7615 - val_loss: 0.5995 - val_accuracy: 0.7727\n",
      "Epoch 40/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6588 - accuracy: 0.7668 - val_loss: 0.5984 - val_accuracy: 0.7714\n",
      "Epoch 41/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6512 - accuracy: 0.7681 - val_loss: 0.5854 - val_accuracy: 0.7797\n",
      "Epoch 42/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6451 - accuracy: 0.7695 - val_loss: 0.5811 - val_accuracy: 0.7766\n",
      "Epoch 43/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6417 - accuracy: 0.7708 - val_loss: 0.5860 - val_accuracy: 0.7755\n",
      "Epoch 44/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6357 - accuracy: 0.7728 - val_loss: 0.5904 - val_accuracy: 0.7761\n",
      "Epoch 45/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6314 - accuracy: 0.7745 - val_loss: 0.5749 - val_accuracy: 0.7807\n",
      "Epoch 46/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6256 - accuracy: 0.7760 - val_loss: 0.5721 - val_accuracy: 0.7784\n",
      "Epoch 47/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6204 - accuracy: 0.7790 - val_loss: 0.5631 - val_accuracy: 0.7845\n",
      "Epoch 48/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6142 - accuracy: 0.7794 - val_loss: 0.5635 - val_accuracy: 0.7850\n",
      "Epoch 49/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6131 - accuracy: 0.7813 - val_loss: 0.5628 - val_accuracy: 0.7868\n",
      "Epoch 50/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6054 - accuracy: 0.7831 - val_loss: 0.5519 - val_accuracy: 0.7912\n"
     ]
    }
   ],
   "source": [
    "history_4 = model_3.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5ef81bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 768, 128)          128000    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 768, 128)          131584    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 309,382\n",
      "Trainable params: 309,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Embedding(1000, 128, input_length = 768))\n",
    "model_4.add(LSTM(128, return_sequences=True))\n",
    "model_4.add(LSTM(64))\n",
    "model_4.add(Dense(6, activation='softmax'))\n",
    "model_4.summary()\n",
    "\n",
    "model_4.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "44345ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1722/1722 [==============================] - 79s 45ms/step - loss: 1.4448 - accuracy: 0.4044 - val_loss: 1.2200 - val_accuracy: 0.5106\n",
      "Epoch 2/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 1.2139 - accuracy: 0.5119 - val_loss: 1.1175 - val_accuracy: 0.5505\n",
      "Epoch 3/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 1.1466 - accuracy: 0.5373 - val_loss: 1.0447 - val_accuracy: 0.5784\n",
      "Epoch 4/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 1.0135 - accuracy: 0.5888 - val_loss: 0.9598 - val_accuracy: 0.6152\n",
      "Epoch 5/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.9628 - accuracy: 0.6097 - val_loss: 0.9353 - val_accuracy: 0.6266\n",
      "Epoch 6/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.9516 - accuracy: 0.6141 - val_loss: 0.9205 - val_accuracy: 0.6325\n",
      "Epoch 7/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.9475 - accuracy: 0.6132 - val_loss: 0.8893 - val_accuracy: 0.6408\n",
      "Epoch 8/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 1.2777 - accuracy: 0.4852 - val_loss: 1.0636 - val_accuracy: 0.5614\n",
      "Epoch 9/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 1.0003 - accuracy: 0.5975 - val_loss: 0.9451 - val_accuracy: 0.6250\n",
      "Epoch 10/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 1.4227 - accuracy: 0.4395 - val_loss: 1.4481 - val_accuracy: 0.4056\n",
      "Epoch 11/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 1.3204 - accuracy: 0.4707 - val_loss: 1.2503 - val_accuracy: 0.4895\n",
      "Epoch 12/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 1.2391 - accuracy: 0.5052 - val_loss: 1.1146 - val_accuracy: 0.5611\n",
      "Epoch 13/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 1.3306 - accuracy: 0.4767 - val_loss: 1.2321 - val_accuracy: 0.5136\n",
      "Epoch 14/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 1.1905 - accuracy: 0.5290 - val_loss: 1.2555 - val_accuracy: 0.4918\n",
      "Epoch 15/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 1.0791 - accuracy: 0.5716 - val_loss: 0.9828 - val_accuracy: 0.6020\n",
      "Epoch 16/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 0.9501 - accuracy: 0.6229 - val_loss: 0.8664 - val_accuracy: 0.6590\n",
      "Epoch 17/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.8942 - accuracy: 0.6473 - val_loss: 0.8794 - val_accuracy: 0.6480\n",
      "Epoch 18/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.8677 - accuracy: 0.6612 - val_loss: 0.9132 - val_accuracy: 0.6351\n",
      "Epoch 19/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.8429 - accuracy: 0.6740 - val_loss: 0.8979 - val_accuracy: 0.6391\n",
      "Epoch 20/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.8264 - accuracy: 0.6825 - val_loss: 0.8032 - val_accuracy: 0.6908\n",
      "Epoch 21/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.8159 - accuracy: 0.6882 - val_loss: 0.8039 - val_accuracy: 0.6954\n",
      "Epoch 22/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.8019 - accuracy: 0.6955 - val_loss: 0.8443 - val_accuracy: 0.6894\n",
      "Epoch 23/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7908 - accuracy: 0.7007 - val_loss: 0.7778 - val_accuracy: 0.7052\n",
      "Epoch 24/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7844 - accuracy: 0.7026 - val_loss: 0.7780 - val_accuracy: 0.7080\n",
      "Epoch 25/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7788 - accuracy: 0.7040 - val_loss: 0.7781 - val_accuracy: 0.7041\n",
      "Epoch 26/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7640 - accuracy: 0.7105 - val_loss: 0.7445 - val_accuracy: 0.7178\n",
      "Epoch 27/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7616 - accuracy: 0.7131 - val_loss: 0.7345 - val_accuracy: 0.7212\n",
      "Epoch 28/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7565 - accuracy: 0.7150 - val_loss: 0.7485 - val_accuracy: 0.7136\n",
      "Epoch 29/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7463 - accuracy: 0.7185 - val_loss: 0.7212 - val_accuracy: 0.7265\n",
      "Epoch 30/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7365 - accuracy: 0.7227 - val_loss: 0.7334 - val_accuracy: 0.7245\n",
      "Epoch 31/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7314 - accuracy: 0.7255 - val_loss: 0.7377 - val_accuracy: 0.7180\n",
      "Epoch 32/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7317 - accuracy: 0.7241 - val_loss: 0.7047 - val_accuracy: 0.7325\n",
      "Epoch 33/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7223 - accuracy: 0.7296 - val_loss: 0.7139 - val_accuracy: 0.7291\n",
      "Epoch 34/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7179 - accuracy: 0.7310 - val_loss: 0.7150 - val_accuracy: 0.7297\n",
      "Epoch 35/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7144 - accuracy: 0.7331 - val_loss: 0.7387 - val_accuracy: 0.7201\n",
      "Epoch 36/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7099 - accuracy: 0.7336 - val_loss: 0.7005 - val_accuracy: 0.7328\n",
      "Epoch 37/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.7001 - accuracy: 0.7371 - val_loss: 0.7054 - val_accuracy: 0.7315\n",
      "Epoch 38/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.6985 - accuracy: 0.7393 - val_loss: 0.7194 - val_accuracy: 0.7265\n",
      "Epoch 39/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.6908 - accuracy: 0.7408 - val_loss: 0.7067 - val_accuracy: 0.7306\n",
      "Epoch 40/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.6863 - accuracy: 0.7419 - val_loss: 0.7056 - val_accuracy: 0.7291\n",
      "Epoch 41/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 0.6855 - accuracy: 0.7436 - val_loss: 0.6680 - val_accuracy: 0.7425\n",
      "Epoch 42/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 0.6743 - accuracy: 0.7469 - val_loss: 0.7215 - val_accuracy: 0.7301\n",
      "Epoch 43/50\n",
      "1722/1722 [==============================] - 77s 45ms/step - loss: 0.6706 - accuracy: 0.7481 - val_loss: 0.7321 - val_accuracy: 0.7242\n",
      "Epoch 44/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 0.6667 - accuracy: 0.7490 - val_loss: 0.6707 - val_accuracy: 0.7426\n",
      "Epoch 45/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 0.6634 - accuracy: 0.7511 - val_loss: 0.7432 - val_accuracy: 0.7191\n",
      "Epoch 46/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 0.6577 - accuracy: 0.7518 - val_loss: 0.6507 - val_accuracy: 0.7482\n",
      "Epoch 47/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 0.6535 - accuracy: 0.7539 - val_loss: 0.6612 - val_accuracy: 0.7462\n",
      "Epoch 48/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 0.6500 - accuracy: 0.7551 - val_loss: 0.6499 - val_accuracy: 0.7536\n",
      "Epoch 49/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 0.6451 - accuracy: 0.7575 - val_loss: 0.6556 - val_accuracy: 0.7492\n",
      "Epoch 50/50\n",
      "1722/1722 [==============================] - 78s 45ms/step - loss: 0.6393 - accuracy: 0.7596 - val_loss: 0.6292 - val_accuracy: 0.7564\n"
     ]
    }
   ],
   "source": [
    "history_5 = model_4.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fc3b5a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61195</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61197</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61199</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5\n",
       "0      0  0  0  0  0  1\n",
       "1      0  0  0  0  1  0\n",
       "2      0  0  0  1  0  0\n",
       "3      0  0  1  0  0  0\n",
       "4      0  0  0  0  1  0\n",
       "...   .. .. .. .. .. ..\n",
       "61195  0  1  0  0  0  0\n",
       "61196  0  0  0  1  0  0\n",
       "61197  0  1  0  0  0  0\n",
       "61198  0  0  1  0  0  0\n",
       "61199  0  0  0  0  1  0\n",
       "\n",
       "[61200 rows x 6 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"Classes_KMeans_4.pkl\", \"rb\") as file_to_read:\n",
    "    classes_KM_1 = pickle.load(file_to_read)\n",
    "    \n",
    "classes_KM_np_1 = np.asarray(classes_KM)\n",
    "classes_KM_np_dum_1 = pd.get_dummies(classes_KM_np_1)\n",
    "classes_KM_np_dum_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "76f97964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 768, 128)          128000    \n",
      "                                                                 \n",
      " gru_18 (GRU)                (None, 768, 128)          99072     \n",
      "                                                                 \n",
      " gru_19 (GRU)                (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,710\n",
      "Trainable params: 264,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(Embedding(1000, 128, input_length = 768))\n",
    "model_5.add(GRU(128, return_sequences=True))\n",
    "model_5.add(GRU(64))\n",
    "model_5.add(Dense(6, activation='softmax'))\n",
    "model_5.summary()\n",
    "\n",
    "model_5.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "24090b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, classes_KM_np_dum_1, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d986342d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1722/1722 [==============================] - 78s 44ms/step - loss: 1.4790 - accuracy: 0.3968 - val_loss: 1.2444 - val_accuracy: 0.5049\n",
      "Epoch 2/50\n",
      "1722/1722 [==============================] - 75s 43ms/step - loss: 1.1619 - accuracy: 0.5341 - val_loss: 1.0457 - val_accuracy: 0.5779\n",
      "Epoch 3/50\n",
      "1722/1722 [==============================] - 75s 44ms/step - loss: 1.0148 - accuracy: 0.5889 - val_loss: 0.9553 - val_accuracy: 0.6080\n",
      "Epoch 4/50\n",
      "1722/1722 [==============================] - 75s 44ms/step - loss: 0.9426 - accuracy: 0.6131 - val_loss: 0.8985 - val_accuracy: 0.6413\n",
      "Epoch 5/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.9163 - accuracy: 0.6247 - val_loss: 0.8786 - val_accuracy: 0.6467\n",
      "Epoch 6/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8980 - accuracy: 0.6323 - val_loss: 0.8761 - val_accuracy: 0.6451\n",
      "Epoch 7/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8810 - accuracy: 0.6403 - val_loss: 0.8547 - val_accuracy: 0.6564\n",
      "Epoch 8/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8677 - accuracy: 0.6467 - val_loss: 0.8392 - val_accuracy: 0.6614\n",
      "Epoch 9/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8530 - accuracy: 0.6515 - val_loss: 0.8350 - val_accuracy: 0.6665\n",
      "Epoch 10/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8398 - accuracy: 0.6597 - val_loss: 0.8310 - val_accuracy: 0.6652\n",
      "Epoch 11/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8285 - accuracy: 0.6653 - val_loss: 0.8023 - val_accuracy: 0.6771\n",
      "Epoch 12/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.8163 - accuracy: 0.6699 - val_loss: 0.8446 - val_accuracy: 0.6600\n",
      "Epoch 13/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7997 - accuracy: 0.6806 - val_loss: 0.7871 - val_accuracy: 0.6894\n",
      "Epoch 14/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7870 - accuracy: 0.6873 - val_loss: 0.8105 - val_accuracy: 0.6721\n",
      "Epoch 15/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7764 - accuracy: 0.6948 - val_loss: 0.7957 - val_accuracy: 0.6819\n",
      "Epoch 16/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7645 - accuracy: 0.6995 - val_loss: 0.7514 - val_accuracy: 0.7116\n",
      "Epoch 17/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7540 - accuracy: 0.7056 - val_loss: 0.7392 - val_accuracy: 0.7127\n",
      "Epoch 18/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7410 - accuracy: 0.7113 - val_loss: 0.7235 - val_accuracy: 0.7206\n",
      "Epoch 19/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7327 - accuracy: 0.7161 - val_loss: 0.7219 - val_accuracy: 0.7186\n",
      "Epoch 20/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7178 - accuracy: 0.7231 - val_loss: 0.6966 - val_accuracy: 0.7312\n",
      "Epoch 21/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7079 - accuracy: 0.7274 - val_loss: 0.7042 - val_accuracy: 0.7312\n",
      "Epoch 22/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.7002 - accuracy: 0.7316 - val_loss: 0.6886 - val_accuracy: 0.7340\n",
      "Epoch 23/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6915 - accuracy: 0.7348 - val_loss: 0.6768 - val_accuracy: 0.7436\n",
      "Epoch 24/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6824 - accuracy: 0.7386 - val_loss: 0.6713 - val_accuracy: 0.7379\n",
      "Epoch 25/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6743 - accuracy: 0.7430 - val_loss: 0.6597 - val_accuracy: 0.7453\n",
      "Epoch 26/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6670 - accuracy: 0.7460 - val_loss: 0.6461 - val_accuracy: 0.7557\n",
      "Epoch 27/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6615 - accuracy: 0.7479 - val_loss: 0.6561 - val_accuracy: 0.7502\n",
      "Epoch 28/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6533 - accuracy: 0.7523 - val_loss: 0.6437 - val_accuracy: 0.7559\n",
      "Epoch 29/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6471 - accuracy: 0.7526 - val_loss: 0.6410 - val_accuracy: 0.7526\n",
      "Epoch 30/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6426 - accuracy: 0.7562 - val_loss: 0.6333 - val_accuracy: 0.7603\n",
      "Epoch 31/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6358 - accuracy: 0.7576 - val_loss: 0.6367 - val_accuracy: 0.7570\n",
      "Epoch 32/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6308 - accuracy: 0.7598 - val_loss: 0.6275 - val_accuracy: 0.7570\n",
      "Epoch 33/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6248 - accuracy: 0.7629 - val_loss: 0.6268 - val_accuracy: 0.7595\n",
      "Epoch 34/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6216 - accuracy: 0.7655 - val_loss: 0.6243 - val_accuracy: 0.7569\n",
      "Epoch 35/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6163 - accuracy: 0.7666 - val_loss: 0.6440 - val_accuracy: 0.7552\n",
      "Epoch 36/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6110 - accuracy: 0.7692 - val_loss: 0.6058 - val_accuracy: 0.7647\n",
      "Epoch 37/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6080 - accuracy: 0.7682 - val_loss: 0.6084 - val_accuracy: 0.7644\n",
      "Epoch 38/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.6025 - accuracy: 0.7723 - val_loss: 0.5937 - val_accuracy: 0.7703\n",
      "Epoch 39/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5996 - accuracy: 0.7724 - val_loss: 0.5981 - val_accuracy: 0.7691\n",
      "Epoch 40/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5934 - accuracy: 0.7748 - val_loss: 0.5890 - val_accuracy: 0.7727\n",
      "Epoch 41/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5886 - accuracy: 0.7765 - val_loss: 0.5915 - val_accuracy: 0.7717\n",
      "Epoch 42/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5839 - accuracy: 0.7792 - val_loss: 0.5817 - val_accuracy: 0.7758\n",
      "Epoch 43/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5790 - accuracy: 0.7804 - val_loss: 0.5929 - val_accuracy: 0.7690\n",
      "Epoch 44/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5750 - accuracy: 0.7829 - val_loss: 0.5756 - val_accuracy: 0.7766\n",
      "Epoch 45/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5695 - accuracy: 0.7831 - val_loss: 0.5789 - val_accuracy: 0.7719\n",
      "Epoch 46/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5648 - accuracy: 0.7854 - val_loss: 0.5609 - val_accuracy: 0.7815\n",
      "Epoch 47/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5608 - accuracy: 0.7861 - val_loss: 0.5643 - val_accuracy: 0.7842\n",
      "Epoch 48/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5567 - accuracy: 0.7876 - val_loss: 0.5548 - val_accuracy: 0.7840\n",
      "Epoch 49/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5544 - accuracy: 0.7891 - val_loss: 0.5677 - val_accuracy: 0.7783\n",
      "Epoch 50/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.5491 - accuracy: 0.7900 - val_loss: 0.5610 - val_accuracy: 0.7796\n"
     ]
    }
   ],
   "source": [
    "history_6 = model_5.fit(X_train_1, y_train_1, batch_size=32, epochs=50, validation_data=(X_test_1,y_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8ef05684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 768, 128)          128000    \n",
      "                                                                 \n",
      " gru_20 (GRU)                (None, 768, 128)          99072     \n",
      "                                                                 \n",
      " gru_21 (GRU)                (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,450\n",
      "Trainable params: 264,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_anom = Sequential()\n",
    "model_anom.add(Embedding(1000, 128, input_length = 768))\n",
    "model_anom.add(GRU(128, return_sequences=True))\n",
    "model_anom.add(GRU(64))\n",
    "model_anom.add(Dense(2, activation='softmax'))\n",
    "model_anom.summary()\n",
    "\n",
    "model_anom.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(0.0001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b754d7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61195</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61196</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61197</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61198</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61199</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0      1  0\n",
       "1      1  0\n",
       "2      0  1\n",
       "3      1  0\n",
       "4      1  0\n",
       "...   .. ..\n",
       "61195  1  0\n",
       "61196  0  1\n",
       "61197  1  0\n",
       "61198  1  0\n",
       "61199  1  0\n",
       "\n",
       "[61200 rows x 2 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"anomaly.pkl\", \"rb\") as file_to_read:\n",
    "    anomaly = pickle.load(file_to_read)\n",
    "    \n",
    "anomaly_np = np.asarray(anomaly)\n",
    "anomaly_np_dum = pd.get_dummies(anomaly_np)\n",
    "anomaly_np_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b442f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_an, X_test_an, y_train_an, y_test_an = train_test_split(X, anomaly_np_dum, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "bb16415a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1722/1722 [==============================] - 77s 44ms/step - loss: 0.2928 - accuracy: 0.9089 - val_loss: 0.1655 - val_accuracy: 0.9477\n",
      "Epoch 2/50\n",
      "1722/1722 [==============================] - 75s 44ms/step - loss: 0.1685 - accuracy: 0.9453 - val_loss: 0.1591 - val_accuracy: 0.9515\n",
      "Epoch 3/50\n",
      "1722/1722 [==============================] - 75s 44ms/step - loss: 0.1591 - accuracy: 0.9490 - val_loss: 0.1596 - val_accuracy: 0.9485\n",
      "Epoch 4/50\n",
      "1722/1722 [==============================] - 75s 44ms/step - loss: 0.1482 - accuracy: 0.9516 - val_loss: 0.1505 - val_accuracy: 0.9508\n",
      "Epoch 5/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1413 - accuracy: 0.9528 - val_loss: 0.1350 - val_accuracy: 0.9549\n",
      "Epoch 6/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1361 - accuracy: 0.9538 - val_loss: 0.1212 - val_accuracy: 0.9605\n",
      "Epoch 7/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1291 - accuracy: 0.9549 - val_loss: 0.1188 - val_accuracy: 0.9611\n",
      "Epoch 8/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1251 - accuracy: 0.9554 - val_loss: 0.1237 - val_accuracy: 0.9582\n",
      "Epoch 9/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1240 - accuracy: 0.9550 - val_loss: 0.1203 - val_accuracy: 0.9569\n",
      "Epoch 10/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1210 - accuracy: 0.9570 - val_loss: 0.1105 - val_accuracy: 0.9623\n",
      "Epoch 11/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1187 - accuracy: 0.9574 - val_loss: 0.1088 - val_accuracy: 0.9613\n",
      "Epoch 12/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1165 - accuracy: 0.9578 - val_loss: 0.1065 - val_accuracy: 0.9614\n",
      "Epoch 13/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1141 - accuracy: 0.9583 - val_loss: 0.1177 - val_accuracy: 0.9547\n",
      "Epoch 14/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1140 - accuracy: 0.9583 - val_loss: 0.1070 - val_accuracy: 0.9611\n",
      "Epoch 15/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1121 - accuracy: 0.9591 - val_loss: 0.1032 - val_accuracy: 0.9624\n",
      "Epoch 16/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1101 - accuracy: 0.9598 - val_loss: 0.1039 - val_accuracy: 0.9619\n",
      "Epoch 17/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1093 - accuracy: 0.9599 - val_loss: 0.1072 - val_accuracy: 0.9595\n",
      "Epoch 18/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1086 - accuracy: 0.9597 - val_loss: 0.1024 - val_accuracy: 0.9621\n",
      "Epoch 19/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1077 - accuracy: 0.9606 - val_loss: 0.1055 - val_accuracy: 0.9637\n",
      "Epoch 20/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1061 - accuracy: 0.9616 - val_loss: 0.1027 - val_accuracy: 0.9631\n",
      "Epoch 21/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1048 - accuracy: 0.9615 - val_loss: 0.1169 - val_accuracy: 0.9529\n",
      "Epoch 22/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1035 - accuracy: 0.9618 - val_loss: 0.0996 - val_accuracy: 0.9641\n",
      "Epoch 23/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1028 - accuracy: 0.9616 - val_loss: 0.0999 - val_accuracy: 0.9639\n",
      "Epoch 24/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1024 - accuracy: 0.9621 - val_loss: 0.1114 - val_accuracy: 0.9623\n",
      "Epoch 25/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1017 - accuracy: 0.9623 - val_loss: 0.1055 - val_accuracy: 0.9596\n",
      "Epoch 26/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1010 - accuracy: 0.9625 - val_loss: 0.0974 - val_accuracy: 0.9632\n",
      "Epoch 27/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1007 - accuracy: 0.9625 - val_loss: 0.0951 - val_accuracy: 0.9644\n",
      "Epoch 28/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1009 - accuracy: 0.9618 - val_loss: 0.0978 - val_accuracy: 0.9637\n",
      "Epoch 29/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.1003 - accuracy: 0.9623 - val_loss: 0.1064 - val_accuracy: 0.9574\n",
      "Epoch 30/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0995 - accuracy: 0.9621 - val_loss: 0.1018 - val_accuracy: 0.9613\n",
      "Epoch 31/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0989 - accuracy: 0.9626 - val_loss: 0.0982 - val_accuracy: 0.9654\n",
      "Epoch 32/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0986 - accuracy: 0.9628 - val_loss: 0.0997 - val_accuracy: 0.9618\n",
      "Epoch 33/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0970 - accuracy: 0.9636 - val_loss: 0.0980 - val_accuracy: 0.9621\n",
      "Epoch 34/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0972 - accuracy: 0.9635 - val_loss: 0.0958 - val_accuracy: 0.9654\n",
      "Epoch 35/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0970 - accuracy: 0.9637 - val_loss: 0.0978 - val_accuracy: 0.9598\n",
      "Epoch 36/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0963 - accuracy: 0.9635 - val_loss: 0.1019 - val_accuracy: 0.9619\n",
      "Epoch 37/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0953 - accuracy: 0.9635 - val_loss: 0.0976 - val_accuracy: 0.9631\n",
      "Epoch 38/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0955 - accuracy: 0.9639 - val_loss: 0.0912 - val_accuracy: 0.9652\n",
      "Epoch 39/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0953 - accuracy: 0.9636 - val_loss: 0.0912 - val_accuracy: 0.9645\n",
      "Epoch 40/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0952 - accuracy: 0.9642 - val_loss: 0.0922 - val_accuracy: 0.9634\n",
      "Epoch 41/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0942 - accuracy: 0.9638 - val_loss: 0.0897 - val_accuracy: 0.9668\n",
      "Epoch 42/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0942 - accuracy: 0.9640 - val_loss: 0.0900 - val_accuracy: 0.9662\n",
      "Epoch 43/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0933 - accuracy: 0.9644 - val_loss: 0.0944 - val_accuracy: 0.9658\n",
      "Epoch 44/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0940 - accuracy: 0.9638 - val_loss: 0.0920 - val_accuracy: 0.9641\n",
      "Epoch 45/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0935 - accuracy: 0.9639 - val_loss: 0.0902 - val_accuracy: 0.9663\n",
      "Epoch 46/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0930 - accuracy: 0.9650 - val_loss: 0.0970 - val_accuracy: 0.9606\n",
      "Epoch 47/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0928 - accuracy: 0.9645 - val_loss: 0.1037 - val_accuracy: 0.9624\n",
      "Epoch 48/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0918 - accuracy: 0.9651 - val_loss: 0.0882 - val_accuracy: 0.9657\n",
      "Epoch 49/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0914 - accuracy: 0.9647 - val_loss: 0.0871 - val_accuracy: 0.9676\n",
      "Epoch 50/50\n",
      "1722/1722 [==============================] - 76s 44ms/step - loss: 0.0912 - accuracy: 0.9651 - val_loss: 0.0869 - val_accuracy: 0.9673\n"
     ]
    }
   ],
   "source": [
    "history_anomaly = model_anom.fit(X_train_an, y_train_an, batch_size=32, epochs=50, validation_data=(X_test_an,y_test_an))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32bab50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-99e4dd8c1792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Input - Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Hidden - Layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bf797e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
